{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_edge_counts = np.load('../../../gabriele/group_edge_counts.npy')\n",
    "group_morphed_obs = np.load('../../../gabriele/group_morphed_obs.npy')\n",
    "\n",
    "cortical_parcels = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_coverage = group_edge_counts[0,-cortical_parcels:, -cortical_parcels:,:]\n",
    "subject_coverage = np.delete(subject_coverage, [0, 51], axis=0)\n",
    "subject_coverage = np.delete(subject_coverage, [0, 51], axis=1)\n",
    "subject_coverage[np.isnan(subject_coverage)] = 0\n",
    "# save edge coverage in separate variable\n",
    "edge_coverage = subject_coverage.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.array(\n",
    "        [\n",
    "            110.        , 130.        , 150.        , 170.        ,\n",
    "            190.        , 210.        , 230.        , 250.        ,\n",
    "            270.        , 290.        , 310.        , 330.        ,\n",
    "            350.        , 370.        , 390.        , 410.        ,\n",
    "            430.        , 450.        \n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladka/anaconda3/envs/sync_states/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: Mean of empty slice\n",
      "/home/vladka/anaconda3/envs/sync_states/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# no matter how many channel one subjects contributes to the overall group mean\n",
    "# if he has one edge, he counts as one subject sampling that edge\n",
    "subject_coverage  = np.sum((subject_coverage > 0).astype(int), axis=-1)\n",
    "corr_splits = np.zeros((3, 100, 4))\n",
    "struct_corr_splits= np.zeros((3, 100, 4))\n",
    "count_ = np.zeros((3, 100, 4))\n",
    "lh_mask = np.zeros((100, 100), dtype=bool)\n",
    "rh_mask = np.zeros((100, 100), dtype=bool)\n",
    "lr_mask = np.zeros((100, 100), dtype=bool)\n",
    "lh_mask[:50, :50] = 1\n",
    "rh_mask[-50:, -50:] = 1\n",
    "lr_mask[:50, -50:] = 1\n",
    "lr_mask[-50:, :50] = 1\n",
    "hemi_mask = np.stack((lh_mask, rh_mask, lr_mask))\n",
    "for subj_threshold in range(1,5):\n",
    "    # read splits from files\n",
    "#     splits = np.genfromtxt('../../../gabriele/At_Least_%d_Subj_per_Schaefer-Edge_BestSplit.csv'%subj_threshold, delimiter=',')\n",
    "    splits = np.load('cov_{}.npy'.format(subj_threshold))\n",
    "    n_splits, n_subjects = splits.shape\n",
    "    for idx in range(n_splits):    \n",
    "        # for each splits get coh1 and coh2 subject indices\n",
    "        coh1_indices = splits[idx,:34].astype(int)\n",
    "        coh2_indices = splits[idx,34:].astype(int)\n",
    "        plv1 = group_morphed_obs[-18:,-cortical_parcels:, -cortical_parcels:,coh1_indices]\n",
    "        plv2 = group_morphed_obs[-18:,-cortical_parcels:, -cortical_parcels:,coh2_indices]\n",
    "        \n",
    "#         plv1 *= group_edge_counts[-18:, -cortical_parcels:, -cortical_parcels:, coh1_indices] > subj_threshold\n",
    "#         plv2 *= group_edge_counts[-18:, -cortical_parcels:, -cortical_parcels:, coh2_indices] > subj_threshold\n",
    "        \n",
    "        plv_coh1 = np.nanmean(plv1, axis=-1)\n",
    "        plv_coh2 = np.nanmean(plv2, axis=-1)\n",
    "        plv_coh1 = np.delete(plv_coh1, [0, 51], axis=1)\n",
    "        plv_coh1 = np.delete(plv_coh1, [0, 51], axis=2)\n",
    "        plv_coh2 = np.delete(plv_coh2, [0, 51], axis=1)\n",
    "        plv_coh2 = np.delete(plv_coh2, [0, 51], axis=2)\n",
    "        # create the full adjaceny matrix such as first dim is cohort\n",
    "        # then frequency x parcel x parcel \n",
    "        plv_grouped = np.stack((plv_coh1, plv_coh2))\n",
    "        # get edges that are sampled by at least \n",
    "        # a min number of subjects            \n",
    "        edge_mask = subject_coverage >= subj_threshold\n",
    "#         plv_grouped[np.isnan(plv_grouped)] = 0\n",
    "        for idx_mask in range(3):\n",
    "            edge_masks_ = np.logical_and(hemi_mask[idx_mask], edge_mask)\n",
    "            count_[idx_mask, subj_threshold-1] = np.sum(edge_masks_)\n",
    "            plv1 = np.nanmean(plv_grouped[0,:,edge_masks_], axis=0)\n",
    "            plv2 = np.nanmean(plv_grouped[1,:,edge_masks_], axis=0)\n",
    "            values_mask = np.logical_and.reduce([plv1 > 0, plv2 > 0])\n",
    "            edge_cov_values1 = edge_coverage[..., coh1_indices ][edge_masks_]\n",
    "            edge_cov_values2 = edge_coverage[..., coh2_indices ][edge_masks_]\n",
    "            struct_corr_splits[idx_mask, idx, subj_threshold-1] = np.corrcoef(edge_cov_values1.sum(axis=1),\n",
    "                                                                             edge_cov_values2.sum(axis=1))[0,1]\n",
    "            corr_splits[idx_mask, idx, subj_threshold-1] = np.corrcoef(plv1[values_mask], \n",
    "                                                                      plv2[values_mask])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = np.zeros((100000, 68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3399221e72fe4865a898bea3a790e248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def _joblib_wrapper(edge_coverage, min_count=1):\n",
    "    orig_indicies = np.arange(68)\n",
    "    np.random.shuffle(orig_indicies)\n",
    "    \n",
    "#     cov_x = np.sum([edge_coverage[..., i]*(edge_coverage[..., i] > min_count) for i in orig_indicies[:34]], axis=0)\n",
    "#     cov_y = np.sum([edge_coverage[..., i]*(edge_coverage[..., i] > min_count) for i in orig_indicies[34:]], axis=0)\n",
    "    \n",
    "    split_idx = np.random.randint(20, 48)\n",
    "    \n",
    "    cov_x = edge_coverage[..., orig_indicies[:split_idx]]*(edge_coverage[..., orig_indicies[:split_idx]] >= min_count)\n",
    "    cov_y = edge_coverage[..., orig_indicies[split_idx:]]*(edge_coverage[..., orig_indicies[split_idx:]] >= min_count)\n",
    "    \n",
    "    cov_x = cov_x.sum(axis=2)\n",
    "    cov_y = cov_y.sum(axis=2)\n",
    "    \n",
    "    mask = np.triu((cov_x > 0) & (cov_y > 0), 1)\n",
    "    coef = np.corrcoef(cov_x[mask], cov_y[mask])[0,1]\n",
    "#     coef = np.sqrt(np.sum(np.power(cov_x[mask] - cov_y[mask], 2)))\n",
    "    \n",
    "    return orig_indicies, coef\n",
    "\n",
    "for cnt in range(1,2):\n",
    "    n_rounds = 100000\n",
    "    results = Parallel(n_jobs=32)(delayed(_joblib_wrapper)(edge_coverage, min_count=cnt) for _ in tqdm.tnrange(n_rounds))\n",
    "\n",
    "    all_splits = np.zeros((n_rounds, 68))\n",
    "    all_coeffs = np.zeros(n_rounds)\n",
    "\n",
    "    for idx, (s, c) in enumerate(results):\n",
    "        all_splits[idx] = s\n",
    "        all_coeffs[idx] = c\n",
    "    \n",
    "    best_splits = all_splits[np.argsort(all_coeffs)[:100]].astype(int)\n",
    "    np.save('cov_{}'.format(cnt), best_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sim_metric(x, y):\n",
    "    xv = x[:34]\n",
    "    yv = y[:34]\n",
    "    \n",
    "    return len(set(xv) ^ set(yv))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
